[{"category":"Models","homepage_url":"https://github.com/allenai/RL4LMs","id":"models--fine-tuning--allenai-rl4lms","logo_url":"http://127.0.0.1:8000/logos/0b22fe6553ffd6c927de0a316a0b01cde01e4c3932170c13bfebb45153f0cdb8.svg","name":"allenai/RL4LMs","subcategory":"Fine tuning","description":"A modular RL library to fine-tune language models to human preferences","repositories":[{"url":"https://github.com/allenai/RL4LMs","primary":true}]},{"category":"Models","homepage_url":"https://github.com/eric-mitchell/direct-preference-optimization","id":"models--fine-tuning--eric-mitchell-direct-preference-optimization","logo_url":"http://127.0.0.1:8000/logos/0b22fe6553ffd6c927de0a316a0b01cde01e4c3932170c13bfebb45153f0cdb8.svg","name":"eric-mitchell/direct-preference-optimization","subcategory":"Fine tuning","description":"Reference implementation for DPO (Direct Preference Optimization)","repositories":[{"url":"https://github.com/eric-mitchell/direct-preference-optimization","primary":true}]},{"category":"Models","homepage_url":"https://github.com/huggingface/peft","id":"models--fine-tuning--huggingface-peft","logo_url":"http://127.0.0.1:8000/logos/0b22fe6553ffd6c927de0a316a0b01cde01e4c3932170c13bfebb45153f0cdb8.svg","name":"huggingface/peft","subcategory":"Fine tuning","description":"ðŸ¤— PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.","repositories":[{"url":"https://github.com/huggingface/peft","primary":true}]}]