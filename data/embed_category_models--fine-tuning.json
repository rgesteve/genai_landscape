{"classification":{"category":{"name":"Models","normalized_name":"models","subcategories":[{"name":"Fine tuning","normalized_name":"fine-tuning"}]}},"foundation":"DEMO","items":[{"category":"Models","id":"models--fine-tuning--huggingface-peft","name":"huggingface/peft","logo":"logos/0b22fe6553ffd6c927de0a316a0b01cde01e4c3932170c13bfebb45153f0cdb8.svg","subcategory":"Fine tuning","website":"https://github.com/huggingface/peft","description":"ðŸ¤— PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.","primary_repository_url":"https://github.com/huggingface/peft"},{"category":"Models","id":"models--fine-tuning--eric-mitchell-direct-preference-optimization","name":"eric-mitchell/direct-preference-optimization","logo":"logos/0b22fe6553ffd6c927de0a316a0b01cde01e4c3932170c13bfebb45153f0cdb8.svg","subcategory":"Fine tuning","website":"https://github.com/eric-mitchell/direct-preference-optimization","description":"Reference implementation for DPO (Direct Preference Optimization)","primary_repository_url":"https://github.com/eric-mitchell/direct-preference-optimization"},{"category":"Models","id":"models--fine-tuning--allenai-rl4lms","name":"allenai/RL4LMs","logo":"logos/0b22fe6553ffd6c927de0a316a0b01cde01e4c3932170c13bfebb45153f0cdb8.svg","subcategory":"Fine tuning","website":"https://github.com/allenai/RL4LMs","description":"A modular RL library to fine-tune language models to human preferences","primary_repository_url":"https://github.com/allenai/RL4LMs"}]}